{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "More about the data :\n",
    "\n",
    "https://pravarmahajan.github.io/fashion/\n",
    "\n",
    "https://juliaml.github.io/MLDatasets.jl/latest/datasets/FashionMNIST/#Contents-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling MLDatasets [eb30cadb-4394-5ae3-aed4-317e484a6458]\n",
      "└ @ Base loading.jl:1273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10-element Array{String,1}:\n",
       " \"T-shirt/top\"\n",
       " \"Trouser\"    \n",
       " \"Pullover\"   \n",
       " \"Dress\"      \n",
       " \"Coat\"       \n",
       " \"Sandal\"     \n",
       " \"Shirt\"      \n",
       " \"Sneaker\"    \n",
       " \"Bag\"        \n",
       " \"Ankle boot\" "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLDatasets, Plots, Images, TestImages\n",
    "\n",
    "train_x, train_y = FashionMNIST.traindata()\n",
    "test_x,  test_y  = FashionMNIST.testdata()\n",
    "\n",
    "# Flatten the matrix input data into a vector\n",
    "X_train = []   # Flattened 784 column vectors\n",
    "Y_train = []   # One-hot encoding label vectors \n",
    "for i = 1:60000\n",
    "    push!(X_train, reshape(train_x[:,:,i], 784))\n",
    "    y = zeros(10)\n",
    "    y[train_y[i] + 1] = 1.0\n",
    "    push!(Y_train,y)\n",
    "end\n",
    "\n",
    "train_data = [x for x in zip(X_train, Y_train)];\n",
    "\n",
    "# Flatten the matrix input data into a vector\n",
    "X_valid = []   # Flattened 784 column vectors\n",
    "Y_valid = []   # One-hot encoding label vectors \n",
    "for i = 1:10000\n",
    "    push!(X_valid, reshape(test_x[:,:,i], 784))\n",
    "    y = zeros(10)\n",
    "    y[test_y[i] + 1] = 1.0\n",
    "    push!(Y_valid,y)\n",
    "end\n",
    "test_data = [x for x in zip(X_valid, Y_valid)];\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\",      \"Shirt\",   \"Sneaker\",  \"Bag\",   \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluation (generic function with 2 methods)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sigmoid(z)\n",
    "    \"\"\" The sigmoid is an activation function that scales the output to this interval [0,1].\"\"\"\n",
    "    return 1/(1+ exp(-z))\n",
    "end\n",
    "\n",
    "function dsigmoid(z)\n",
    "    \"\"\" Sigmoid derivative \"\"\"\n",
    "    return sigmoid(z) * (1-sigmoid(z))\n",
    "end\n",
    "\n",
    "\n",
    "function forward_pass(W, b, x)\n",
    "    \"\"\" This function is used for prediction\n",
    "        Z = W'X + B\n",
    "        A = Sigmoid(Z)\n",
    "        The last entry of A is a vector of probabilities\"\"\"\n",
    "    Z = [[0.0]]\n",
    "    A = [x[1]]\n",
    "    for i = 2:size(W)[1]\n",
    "        push!(Z, W[i]*A[i-1] + b[i])\n",
    "        push!(A, sigmoid.(Z[i]))\n",
    "    end\n",
    "    return Z, A\n",
    "end\n",
    "\n",
    "\n",
    "function quadratic_cost(prediction,real_label)\n",
    "    \"\"\" This is the cost calculation for a single training entry.\"\"\"\n",
    "    return (0.5) * sum((real_label[i] - prediction[i])^2 for i = 1:length(prediction))\n",
    "end\n",
    "    \n",
    "\n",
    "function total_quadratic_cost(labeled_data,W,b)\n",
    "    \"\"\" This is the average cost across every training entry \"\"\"\n",
    "    cost = 0\n",
    "    for i = 1:length(labeled_data)\n",
    "        Z, A = forward_pass(W, b,labeled_data[i])\n",
    "        aL = A[length(A)]\n",
    "        cost += quadratic_cost(aL,labeled_data[i][2])\n",
    "    end\n",
    "    return cost/length(labeled_data)\n",
    "end\n",
    "\n",
    "function output_error(W,b,x,A,Z)\n",
    "    \"\"\"Equation for the error in the output layer.\n",
    "        aLj - yj: is the error of neuron j and the \n",
    "        derivative of cost in respect to the activaction on neuron j and layer L.\n",
    "        dsigmoid(zLj): derivative of sigmoid given pre-activation on neuron and \n",
    "        layer j,L - measures hor fast the activation function sigmoid is chaging at zLj.\"\"\"\n",
    "    return (A[end] - x[2]).*dsigmoid.(Z[end])\n",
    "end\n",
    "\n",
    "function back_prop(W, b, x) \n",
    "    \"\"\" Given the prediction (feed foward), and the output error, the derivative of cost function in respect \n",
    "    to bias and weights is found. This is needed to update the weights and bias.\"\"\"\n",
    "    Z, A = forward_pass(W, b, x)\n",
    "    L = length(weights)\n",
    "    deltas = Dict()\n",
    "    deltas[L] = (A[end] - x[2]).*dsigmoid.(Z[end]) #hadamard_product \n",
    "    for i = L-1:-1:2\n",
    "        deltas[i] = (W[i+1]'*deltas[i+1]).*dsigmoid.(Z[i])\n",
    "    end\n",
    "    return A, deltas\n",
    "end\n",
    "\n",
    "function stochastic_gradient_descent(W, b, data_set, batch_size, epochs, n, save_cost = true)\n",
    "    \"\"\" Gradient descent applied to a random batch of training samples.\n",
    "        This function updates the weights and bias\"\"\"\n",
    "    \n",
    "    W_new = copy(W)\n",
    "    b_new = copy(b)\n",
    "    L = length(W)\n",
    "    \n",
    "    if save_cost == true\n",
    "        cost_points = [(0,total_quadratic_cost(data_set,W,b))]\n",
    "\n",
    "        for j = 1:epochs\n",
    "            k = rand(1:size(data_set)[1]-batch_size)\n",
    "            batch = data_set[k:k+batch_size]\n",
    "            for x in batch\n",
    "                A, deltas = back_prop(W_new, b_new, x) \n",
    "                for i = L:-1:2\n",
    "                    W_new[i] -= (n/batch_size)*deltas[i]*A[i-1]'\n",
    "                    b_new[i] -= (n/batch_size)*deltas[i]\n",
    "                end \n",
    "            end\n",
    "            push!(cost_points, (j, total_quadratic_cost(data_set,W_new,b_new)))\n",
    "        end\n",
    "        return W_new, b_new , cost_points\n",
    "        \n",
    "    else\n",
    "        for j = 1:epochs\n",
    "            k = rand(1:size(data_set)[1]-batch_size)\n",
    "            batch = data_set[k:k+batch_size]\n",
    "            for x in batch\n",
    "                A, deltas = back_prop(W_new, b_new, x) \n",
    "                for i = L:-1:2\n",
    "                    W_new[i] -= (n/batch_size)*deltas[i]*A[i-1]'\n",
    "                    b_new[i] -= (n/batch_size)*deltas[i]\n",
    "                end \n",
    "            end\n",
    "        end\n",
    "\n",
    "        return W_new, b_new\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function random_predict(W, b, x)\n",
    "    i = rand(1:length(x))\n",
    "    Z, A = forward_pass(W, b, x[i])\n",
    "    println(\"Predicted class:\",class_names[argmax(A[end])])\n",
    "    println(\"Actual class:\", class_names[argmax(x[i][2])])\n",
    "    return colorview(Gray, train_x[:,:,i]')\n",
    "end\n",
    "\n",
    "function predict(W, b, x,i)\n",
    "    Z, A = forward_pass(W, b, x[i])\n",
    "    return argmax(A[end])- 1 \n",
    "end\n",
    "\n",
    "function evaluation(W,b,x,train = true)\n",
    "    \"\"\" Calculate Accuracy and Error for training(true)and test set (false). \"\"\"\n",
    "    if train == true\n",
    "        accuracy = 0\n",
    "        for i = 1:length(train_data)\n",
    "            accuracy += sum( predict(W_new,b_new,train_data,i) == train_y[i] )\n",
    "        end\n",
    "        println(\"-----------------------------------------\")\n",
    "        println(\"Training Accuracy   |\",\" Training Error\")\n",
    "        println(\"     \",\n",
    "            round.(accuracy/length(train_data); digits =3),\n",
    "            \"          |\",\n",
    "            \"     \",\n",
    "            round.(1 - accuracy/length(train_data);digits=3))\n",
    "        println(\"-----------------------------------------\")\n",
    "    else\n",
    "        accuracy = 0\n",
    "        for i = 1:length(test_data)\n",
    "            accuracy += sum( predict(W_new,b_new,test_data,i) == test_y[i] )\n",
    "        end\n",
    "        println(\"-----------------------------------------\")\n",
    "        println(\"Validation Accuracy |\",\" Validation Error\")\n",
    "        println(\"     \",\n",
    "            round.(accuracy/length(test_data); digits =3),\n",
    "            \"          |\",\n",
    "            \"     \",\n",
    "            round.(1 - accuracy/length(test_data);digits=3))\n",
    "        println(\"-----------------------------------------\")\n",
    "    end\n",
    "end\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training!\n"
     ]
    }
   ],
   "source": [
    "#weights = [[0.0],randn(60,784),randn(32,60),randn(10,32),randn(10,10)]\n",
    "#weights = [[0.0],randn(200,784),randn(100,200),randn(60,100),randn(32,60),randn(10,32)]\n",
    "weights = [[0.0],randn(60,784),randn(40,60),randn(10,40)] \n",
    "bias    = [[0.0], randn(60),randn(40),randn(10)]\n",
    "W_new, b_new, cost =stochastic_gradient_descent(weights, bias,train_data, 10000, 100,700)\n",
    "println(\"Done Training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of cost function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip0500\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip0500)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip0501\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip0500)\" d=\"\n",
       "M242.516 1425.62 L2352.76 1425.62 L2352.76 121.675 L242.516 121.675  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip0502\">\n",
       "    <rect x=\"242\" y=\"121\" width=\"2111\" height=\"1305\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  302.24,1425.62 302.24,121.675 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  799.938,1425.62 799.938,121.675 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1297.64,1425.62 1297.64,121.675 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1795.33,1425.62 1795.33,121.675 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2293.03,1425.62 2293.03,121.675 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  242.516,1218.85 2352.76,1218.85 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  242.516,970.489 2352.76,970.489 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  242.516,722.131 2352.76,722.131 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  242.516,473.774 2352.76,473.774 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  242.516,225.417 2352.76,225.417 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,1425.62 2352.76,1425.62 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,1425.62 242.516,121.675 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  302.24,1425.62 302.24,1409.97 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  799.938,1425.62 799.938,1409.97 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1297.64,1425.62 1297.64,1409.97 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1795.33,1425.62 1795.33,1409.97 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2293.03,1425.62 2293.03,1409.97 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,1218.85 267.839,1218.85 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,970.489 267.839,970.489 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,722.131 267.839,722.131 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,473.774 267.839,473.774 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip0500)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  242.516,225.417 267.839,225.417 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 302.24, 1479.62)\" x=\"302.24\" y=\"1479.62\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 799.938, 1479.62)\" x=\"799.938\" y=\"1479.62\">25</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1297.64, 1479.62)\" x=\"1297.64\" y=\"1479.62\">50</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1795.33, 1479.62)\" x=\"1795.33\" y=\"1479.62\">75</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2293.03, 1479.62)\" x=\"2293.03\" y=\"1479.62\">100</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 218.516, 1236.35)\" x=\"218.516\" y=\"1236.35\">0.25</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 218.516, 987.989)\" x=\"218.516\" y=\"987.989\">0.50</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 218.516, 739.631)\" x=\"218.516\" y=\"739.631\">0.75</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 218.516, 491.274)\" x=\"218.516\" y=\"491.274\">1.00</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 218.516, 242.917)\" x=\"218.516\" y=\"242.917\">1.25</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:84px; text-anchor:middle;\" transform=\"rotate(0, 1297.64, 73.2)\" x=\"1297.64\" y=\"73.2\">epochs = 100, batch size = 10000, Lr = 0.7</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(0, 1297.64, 1559.48)\" x=\"1297.64\" y=\"1559.48\">Epochs</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip0500)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(-90, 89.2861, 773.647)\" x=\"89.2861\" y=\"773.647\">Cost</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip0502)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  302.24,158.579 322.148,1231.78 342.056,1290.64 361.964,1302.49 381.872,1316.78 401.78,1316.78 421.688,1326.84 441.596,1333.72 461.504,1327.32 481.411,1327.47 \n",
       "  501.319,1330.52 521.227,1341.31 541.135,1345.35 561.043,1347.59 580.951,1345.17 600.859,1353.39 620.767,1333.66 640.675,1349.06 660.583,1351.19 680.491,1357.85 \n",
       "  700.399,1354.56 720.306,1353.21 740.214,1358.04 760.122,1354.99 780.03,1360.59 799.938,1362 819.846,1357.21 839.754,1365.93 859.662,1363.51 879.57,1365.49 \n",
       "  899.478,1366.35 919.386,1360.11 939.294,1367.79 959.202,1359.6 979.109,1366.02 999.017,1362.43 1018.93,1368.63 1038.83,1363.7 1058.74,1365.31 1078.65,1368.62 \n",
       "  1098.56,1364.6 1118.46,1370.37 1138.37,1369.26 1158.28,1374.25 1178.19,1373.71 1198.1,1374.69 1218,1374.8 1237.91,1372.44 1257.82,1371.88 1277.73,1374.1 \n",
       "  1297.64,1375.18 1317.54,1373.28 1337.45,1375.25 1357.36,1366.75 1377.27,1376.88 1397.18,1361.37 1417.08,1377.52 1436.99,1371.57 1456.9,1375.01 1476.81,1378.81 \n",
       "  1496.72,1366.01 1516.62,1366.55 1536.53,1374.28 1556.44,1379.52 1576.35,1374.41 1596.25,1379.29 1616.16,1379.39 1636.07,1376.51 1655.98,1372.78 1675.89,1376.56 \n",
       "  1695.79,1375.87 1715.7,1379.88 1735.61,1372.98 1755.52,1382.41 1775.43,1376.8 1795.33,1381.66 1815.24,1375.24 1835.15,1383.39 1855.06,1381.74 1874.97,1382.69 \n",
       "  1894.87,1383.57 1914.78,1383.98 1934.69,1382.08 1954.6,1373.21 1974.51,1382.2 1994.41,1383.78 2014.32,1384.3 2034.23,1382.77 2054.14,1384.41 2074.05,1386.41 \n",
       "  2093.95,1384.49 2113.86,1379.55 2133.77,1385.65 2153.68,1381.05 2173.58,1384.76 2193.49,1385.13 2213.4,1384.51 2233.31,1385.35 2253.22,1388.34 2273.12,1388.71 \n",
       "  2293.03,1384.93 \n",
       "  \"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(cost, \n",
    "     xaxis = \"Epochs\", \n",
    "    yaxis = \"Cost\",\n",
    "    title = \"epochs = 100, batch size = 10000, Lr = 0.7\",\n",
    "    legend = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Validation Accuracy | Validation Error\n",
      "     0.851          |     0.149\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "Training Accuracy   | Training Error\n",
      "     0.889          |     0.111\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluation(W_new,b_new,train_data,false)\n",
    "evaluation(W_new,b_new,train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class:Shirt\n",
      "Actual class:Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "28×28 reinterpret(Gray{N0f8}, ::LinearAlgebra.Adjoint{Normed{UInt8,8},Array{Normed{UInt8,8},2}}):\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                                  \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_predict(W_new,b_new,train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
